{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_string = \"postgresql://postgres:postgres@postgres/postgres\"\n",
    "# db_string = \"postgresql://postgres:postgres@postgres/dev4slack\"\n",
    "db = create_engine(db_string)\n",
    "\n",
    "def query_df(line_query, cell_query=None, conn=db):\n",
    "    if cell_query==None:\n",
    "      return pd.read_sql(line_query, conn)\n",
    "    return pd.read_sql(cell_query, conn)\n",
    "\n",
    "# Custom notebook magic commands for loading sql.\n",
    "from IPython.core.magic import register_line_cell_magic\n",
    "def create_df_sql_magic(magic_name, conn):\n",
    "    def sql_df(line_query, cell_query=None, conn=db):\n",
    "        if cell_query==None:\n",
    "          return pd.read_sql(line_query, conn)\n",
    "        return pd.read_sql(cell_query, conn)\n",
    "    custom_func = sql_df\n",
    "    custom_func.__name__ = magic_name\n",
    "    register_line_cell_magic(custom_func)\n",
    "create_df_sql_magic('sql_df', db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hired_query = \\\n",
    "'''\n",
    "SELECT \n",
    "    message.text AS p_text, message.reply_count, message.user_id as p_id, message.ts,\n",
    "    reply.text AS c_text, reply.user_id as c_id\n",
    "FROM message\n",
    "LEFT JOIN reply on reply.thread_ts=message.ts\n",
    "WHERE message.channel_id='CB6GPKRPT' AND message.reply_count > 0\n",
    "ORDER BY message.ts, reply.ts;\n",
    "'''\n",
    "df = query_df(hired_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new column of replies to each element in c_text.\n",
    "df['replies'] = df.c_text.shift(-1)\n",
    "\n",
    "# Drop rows where a reply refers to an unrelated parent.\n",
    "df = df.groupby('ts', as_index=False).apply(lambda x: x.iloc[:-1])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset=['p_text'])\n",
    "df = df[['p_text']]\n",
    "mask = df['p_text'].str.len() > 1000\n",
    "df = df[mask]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df.p_text.str.contains('Happy Friday')\n",
    "df = df[~mask]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = \"\"\"Good Evening Lambda Fam! I will keep this as short as possible as to save space for other future new hires! Just wanted to say wayyy back July of 2018 when WEBPT2 started, I made it a goal to be able post in here. Many many nights of working late, and grinding, little by little I kept learning new things.There were times when quitting would have been much easier, but it’s never been a part of who I am and it’s never been a part of who you are either. Keep plowing forward relentlessly. I started job searching late November, fell flat on my face a couple times in interviews since I wasn’t familiar with the technical interview format, didn’t know what to expect. When this happened, I went back and figured out what went wrong, and how I can improve.I recently accepted a React Dev job in Dublin, OH and I’m excited, but I realize this is just the start of my learning journey. There is much more to learn on my goal to becoming a senior web developer one day. Always stay curious, never stop learning.I just want to thank all of the Lambda Staff, a few that stand out are @dan.frehner, you’re an amazing teacher, loved every JS and React lesson we had. @Elissa thanks for explaining CS topics so well and making them very understandable. @Diandra Ryan-Mas thank you for all the songs and excellent back end and testing lessons. All the TL’s that served in WebPT2 @KingAtoki @Julian and so many more.  Thanks to Lambda for believing in me, and taking a chance on me out of the 1000's of applicants to the program. I am forever grateful.Lastly, thanks to all the career folks, @Meaghan Barber @Kelsey @Austin Lieberman and everyone else! You all are amazing.Lastly, thanks to all the amazing students in WebPT12 for all the kind words. We have had so much fun in after-hours stretching our learning together. Thanks @Keiran Kozlowski for being so supportive, and @Michael and @KingAtoki once again for being amazing SL’s in that section. TL for the two units I did was some of the most fun I’ve had professionally. I can’t wait to see everyone in this cohort light up the hired board real soon!!\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vec = TfidfVectorizer()\n",
    "# example_vec = vec.fit_transform([example])\n",
    "# df['vecs'] = vec.transform(df.p_text)\n",
    "\n",
    "# cosine_similarity(df.vecs, pd.DataFrame(len(df) * example_vec[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('hired')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "choices = df.p_text.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(random.choice(choices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
