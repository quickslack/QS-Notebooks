{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# restart kernel after this\n",
    "!pip install wget annoy\n",
    "!pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this in cli\n",
    "#pip install gpustat && watch -n 0.1 -c gpustat -cp --color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for loading in slack data and cleaning\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "from multiprocessing import Pool\n",
    "\n",
    "# for creating embeddings and index\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from annoy import AnnoyIndex\n",
    "import numpy as np\n",
    "import subprocess\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# for downloading/extracting model from s3\n",
    "import tarfile\n",
    "import tempfile\n",
    "from transformers import cached_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(637568, 2)\n"
     ]
    }
   ],
   "source": [
    "db_string = \"postgresql://postgres:postgres@postgres/postgres\"\n",
    "db = create_engine(db_string)\n",
    "\n",
    "def query_df(line_query, cell_query=None, conn=db):\n",
    "    if cell_query==None:\n",
    "      return pd.read_sql(line_query, conn)\n",
    "    return pd.read_sql(cell_query, conn)\n",
    "\n",
    "parent_query = 'SELECT * FROM message;'\n",
    "reply_query = 'SELECT * FROM reply;'\n",
    "\n",
    "parents = query_df(parent_query)\n",
    "replies = query_df(reply_query)\n",
    "\n",
    "df = pd.concat([parents, replies])\n",
    "df = df[['message_id', 'text']]\n",
    "assert df.isna().sum().sum() == 0\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_whitespace(text):\n",
    "    for r in ((\"\\t\", \" \"), (\"\\n\", \" \"), ('\"', '')):\n",
    "        text = text.replace(*r)\n",
    "    return text\n",
    "\n",
    "def no_url(text):\n",
    "    tokens = text.split()\n",
    "    new = []\n",
    "    for t in tokens:\n",
    "        if 'http' in t:\n",
    "            new.append('<URL>')        \n",
    "        else:\n",
    "            new.append(t)\n",
    "    clean = ' '.join(new)\n",
    "    return clean\n",
    "\n",
    "def no_short_reply(text):\n",
    "    if len(text) < 30:\n",
    "        text = None\n",
    "    return text\n",
    "\n",
    "def cleaner(series):\n",
    "    series = series.apply(no_whitespace)\n",
    "    series = series.apply(no_url)\n",
    "    series = series.apply(no_short_reply)\n",
    "    return series\n",
    "\n",
    "def fast_clean(df):\n",
    "    with Pool(16) as p:\n",
    "        seq = [df.text]\n",
    "        listy = p.map(cleaner, seq)\n",
    "        results = [pd.Series(i) for i in listy]\n",
    "        clean = results[0]\n",
    "    return clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 574 ms, sys: 4.06 s, total: 4.64 s\n",
      "Wall time: 8.37 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df['cleaned'] = fast_clean(df)\n",
    "df = df.dropna()\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 289 ms, sys: 94.5 ms, total: 384 ms\n",
      "Wall time: 385 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "426855"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Drop questions longer than 510 characters.\n",
    "# df = df.loc[df['cleaned'].str.len() < 511]\n",
    "\n",
    "# Shorten messages.\n",
    "df['cleaned'] = df['cleaned'].str.slice(0,510)\n",
    "\n",
    "# Reset index.\n",
    "df = df.reset_index()\n",
    "\n",
    "# Get a list of all the posts/messages.\n",
    "corpus = list(df.cleaned)\n",
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # bert_m_ids = df[['message_id']]\n",
    "# bert_m_ids.to_csv('bert_m_ids.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.6 s, sys: 23.7 ms, total: 5.62 s\n",
      "Wall time: 5.64 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(426855, 88434)"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "vecs = tfidf.fit_transform(df.cleaned)\n",
    "vecs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29.9 s, sys: 34.5 s, total: 1min 4s\n",
      "Wall time: 19.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(426855, 100)"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "svd = TruncatedSVD(n_components=100)\n",
    "reduced = svd.fit_transform(vecs)\n",
    "reduced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.37 s, sys: 405 ms, total: 2.78 s\n",
      "Wall time: 2.59 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): DistilBERT(\n",
       "    (bert): DistilBertModel(\n",
       "      (embeddings): Embeddings(\n",
       "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (transformer): Transformer(\n",
       "        (layer): ModuleList(\n",
       "          (0): TransformerBlock(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (attention): MultiHeadSelfAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "          (1): TransformerBlock(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (attention): MultiHeadSelfAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "          (2): TransformerBlock(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (attention): MultiHeadSelfAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "          (3): TransformerBlock(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (attention): MultiHeadSelfAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "          (4): TransformerBlock(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (attention): MultiHeadSelfAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "          (5): TransformerBlock(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (attention): MultiHeadSelfAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): Pooling()\n",
       ")"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "url = 'https://model-2.s3.us-east-2.amazonaws.com/distil-bert-SO.tar.gz'\n",
    "\n",
    "def download_pretrained_model():\n",
    "    \"\"\" Download and extract finetuned model from S3 \"\"\"\n",
    "    # most of this func from https://github.com/huggingface/transfer-learning-conv-ai/blob/master/utils.py\n",
    "    resolved_archive_file = cached_path(url)\n",
    "    tempdir = tempfile.mkdtemp()\n",
    "    with tarfile.open(resolved_archive_file, 'r:gz') as archive:\n",
    "        archive.extractall(tempdir)\n",
    "    return os.path.join(tempdir, 'model')\n",
    "\n",
    "embedder = SentenceTransformer(download_pretrained_model())\n",
    "embedder.to(\"cuda\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = 'test1'\n",
    "embedder = SentenceTransformer(model_save_path)\n",
    "embedder.to(\"cuda\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8min 39s, sys: 40 s, total: 9min 19s\n",
      "Wall time: 9min 20s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(426855, 768)"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "corpus_embeddings = embedder.encode(corpus)\n",
    "embs = np.asarray(corpus_embeddings)\n",
    "embs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined = np.concatenate((embs, reduced),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(426855, 868)"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "CPU times: user 1min, sys: 2.84 s, total: 1min 3s\n",
      "Wall time: 1min 3s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# num_docs, vec_dim = combined.shape\n",
    "num_docs, vec_dim = embs.shape\n",
    "\n",
    "distance_measure_type = 'angular'\n",
    "\n",
    "indx = AnnoyIndex(vec_dim, distance_measure_type)\n",
    "for i in range(num_docs):\n",
    "    indx.add_item(i, embs[i])\n",
    "\n",
    "num_trees = int(np.log(num_docs).round(0))\n",
    "# num_trees = 100\n",
    "print(num_trees)\n",
    "indx.build(num_trees)\n",
    "index_name = f'dim{vec_dim}-trees{num_trees}'\n",
    "index_file = f'{index_name}.ann'\n",
    "indx.save(index_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # compress index\n",
    "# compressed_name = f'{index_name}.tar.gz'\n",
    "# command = f'tar czvf {compressed_name} {index_file}'\n",
    "# subprocess.check_output(command.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !tar -xzvf dim768-trees13.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Will do, Ill post a link for all of us as soon as the BW meeting ends\n",
      "97231 Ill will pull now as see if it still fits well\n",
      "180632 will do! I am about half finished with the styling\n",
      "363171 Will do! She has the pix on her phone so I'll leave that post to her and chime in when necessary\n",
      "196180 I still dont elijah had to go do something i dont know if he can\n",
      "161888 Be right there, had to vacate my apt for a few minutes\n",
      "152628 im going to let yall keep working , we can do our final stand up tomorrow\n",
      "66120 gonna use it to badger my players to start up again\n",
      "103943 I'm fine with that approach, we'd just have to work out scheduling\n",
      "27369 Hope everyone had a good build week and JS assessment. Almost the weekend! <URL>\n",
      "CPU times: user 16.2 ms, sys: 31.7 ms, total: 47.9 ms\n",
      "Wall time: 45.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "index = AnnoyIndex(vec_dim, distance_measure_type)\n",
    "index.load(index_file)\n",
    "for i in index.get_nns_by_item(0,10):\n",
    "    print(i, df.cleaned[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = ['deploy to heroku']\n",
    "# vec = tfidf.transform(example)\n",
    "# vec = svd.transform(vec)\n",
    "\n",
    "emb = embedder.encode(example)\n",
    "emb = np.asarray(emb)\n",
    "\n",
    "# combined_example = np.concatenate((emb, vec), axis=1)\n",
    "# combined_example.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74454 landing page connected -&gt; <URL>\n",
      "231048 establish dependencies being used on monday\n",
      "178635 hover over the lower left side of the zoom window\n",
      "129119 Landing page - <URL> Front-end - <URL>\n",
      "391514 Landing page - <URL> Front-end - <URL>\n",
      "377151 ensure only natural numbers and not floats?\n",
      "285580 Buttons, that’s a good idea, in a pinch\n",
      "279620 Moving the function inside cleared my error\n",
      "146177 Backend incoming guys doing some final testing\n",
      "410958 Backend incoming guys doing some final testing\n",
      "54888 landing-page , login-screen, signup-form\n",
      "143625 scores, category, random questions,\n",
      "60483 Calculating integer factorials in constant time, taking advantage of overflow behavior <URL>\n",
      "66219 Material Design Bootstrap …and styled-components\n",
      "66211 Material UI comes with some PRO components\n",
      "276645 scoring on the thousandth % range?? haha\n",
      "72898 Technical Design Document <URL>\n",
      "225262 yarn add node-sass and still getting error\n",
      "17948 yarn add node-sass and still getting error\n",
      "338129 250 live weight so probably 180 or so after dressed\n",
      "CPU times: user 632 µs, sys: 4.1 ms, total: 4.73 ms\n",
      "Wall time: 3.63 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in index.get_nns_by_vector(emb.ravel(), 20): # Gets the top 5 similar to unseen example embedding\n",
    "#     print('\\n')\n",
    "    print(i, df.cleaned[i])\n",
    "\n",
    "# Search query: 'tensorflow in production'\n",
    "# Cherry-picked result from the above query w/ full sized embeddings:\n",
    "# '119220 Deploy machine learning models as web servers. <URL>'\n",
    "# None of the words are from the query, but the result has a similar meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
