{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# restart kernel after this\n",
    "!pip install wget annoy\n",
    "!pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this in cli\n",
    "#pip install gpustat && watch -n 0.1 -c gpustat -cp --color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for loading in slack data and cleaning\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "from multiprocessing import Pool\n",
    "\n",
    "# for creating embeddings and index\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from annoy import AnnoyIndex\n",
    "import numpy as np\n",
    "import subprocess\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# for downloading/extracting model from s3\n",
    "import tarfile\n",
    "import tempfile\n",
    "from transformers import cached_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(637568, 2)\n"
     ]
    }
   ],
   "source": [
    "db_string = \"postgresql://postgres:postgres@postgres/postgres\"\n",
    "db = create_engine(db_string)\n",
    "\n",
    "def query_df(line_query, cell_query=None, conn=db):\n",
    "    if cell_query==None:\n",
    "      return pd.read_sql(line_query, conn)\n",
    "    return pd.read_sql(cell_query, conn)\n",
    "\n",
    "parent_query = 'SELECT * FROM message;'\n",
    "reply_query = 'SELECT * FROM reply;'\n",
    "\n",
    "parents = query_df(parent_query)\n",
    "replies = query_df(reply_query)\n",
    "\n",
    "df = pd.concat([parents, replies])\n",
    "df = df[['message_id', 'text']]\n",
    "assert df.isna().sum().sum() == 0\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_whitespace(text):\n",
    "    for r in ((\"\\t\", \" \"), (\"\\n\", \" \"), ('\"', '')):\n",
    "        text = text.replace(*r)\n",
    "    return text\n",
    "\n",
    "def no_url(text):\n",
    "    tokens = text.split()\n",
    "    new = []\n",
    "    for t in tokens:\n",
    "        if 'http' in t:\n",
    "            new.append('<URL>')        \n",
    "        else:\n",
    "            new.append(t)\n",
    "    clean = ' '.join(new)\n",
    "    return clean\n",
    "\n",
    "def no_short_reply(text):\n",
    "    if len(text) < 30:\n",
    "        text = None\n",
    "    return text\n",
    "\n",
    "def cleaner(series):\n",
    "    series = series.apply(no_whitespace)\n",
    "    series = series.apply(no_url)\n",
    "    series = series.apply(no_short_reply)\n",
    "    return series\n",
    "\n",
    "def fast_clean(df):\n",
    "    with Pool(16) as p:\n",
    "        seq = [df.text]\n",
    "        listy = p.map(cleaner, seq)\n",
    "        results = [pd.Series(i) for i in listy]\n",
    "        clean = results[0]\n",
    "    return clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 599 ms, sys: 377 ms, total: 976 ms\n",
      "Wall time: 3.77 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df['cleaned'] = fast_clean(df)\n",
    "df = df.dropna()\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 249 ms, sys: 0 ns, total: 249 ms\n",
      "Wall time: 248 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "426855"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Drop questions longer than 510 characters.\n",
    "# df = df.loc[df['cleaned'].str.len() < 511]\n",
    "\n",
    "# Shorten messages.\n",
    "df['cleaned'] = df['cleaned'].str.slice(0,510)\n",
    "\n",
    "# Reset index.\n",
    "df = df.reset_index()\n",
    "\n",
    "# Get a list of all the posts/messages.\n",
    "corpus = list(df.cleaned)\n",
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # bert_m_ids = df[['message_id']]\n",
    "# bert_m_ids.to_csv('bert_m_ids.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.6 s, sys: 23.7 ms, total: 5.62 s\n",
      "Wall time: 5.64 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(426855, 88434)"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%time\n",
    "# tfidf = TfidfVectorizer(stop_words='english')\n",
    "# vecs = tfidf.fit_transform(df.cleaned)\n",
    "# vecs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29.9 s, sys: 34.5 s, total: 1min 4s\n",
      "Wall time: 19.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(426855, 100)"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%time\n",
    "# svd = TruncatedSVD(n_components=100)\n",
    "# reduced = svd.fit_transform(vecs)\n",
    "# reduced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# url = 'https://model-2.s3.us-east-2.amazonaws.com/distil-bert-SO.tar.gz'\n",
    "\n",
    "# def download_pretrained_model():\n",
    "#     \"\"\" Download and extract finetuned model from S3 \"\"\"\n",
    "#     # most of this func from https://github.com/huggingface/transfer-learning-conv-ai/blob/master/utils.py\n",
    "#     resolved_archive_file = cached_path(url)\n",
    "#     tempdir = tempfile.mkdtemp()\n",
    "#     with tarfile.open(resolved_archive_file, 'r:gz') as archive:\n",
    "#         archive.extractall(tempdir)\n",
    "#     return os.path.join(tempdir, 'model')\n",
    "\n",
    "# embedder = SentenceTransformer(download_pretrained_model())\n",
    "# embedder.to(\"cuda\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = 'test1'\n",
    "embedder = SentenceTransformer(model_save_path)\n",
    "embedder.to(\"cuda\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8min 46s, sys: 54 s, total: 9min 40s\n",
      "Wall time: 9min 40s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(426855, 768)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "corpus_embeddings = embedder.encode(corpus)\n",
    "embs = np.asarray(corpus_embeddings)\n",
    "embs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined = np.concatenate((embs, reduced),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(426855, 868)"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "CPU times: user 1min 32s, sys: 1.94 s, total: 1min 34s\n",
      "Wall time: 1min 34s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# num_docs, vec_dim = combined.shape\n",
    "num_docs, vec_dim = embs.shape\n",
    "\n",
    "distance_measure_type = 'angular'\n",
    "\n",
    "indx = AnnoyIndex(vec_dim, distance_measure_type)\n",
    "for i in range(num_docs):\n",
    "    indx.add_item(i, embs[i])\n",
    "\n",
    "num_trees = int(np.log(num_docs).round(0))\n",
    "# num_trees = 100\n",
    "print(num_trees)\n",
    "indx.build(num_trees)\n",
    "index_name = f'dim{vec_dim}-trees{num_trees}'\n",
    "index_file = f'{index_name}.ann'\n",
    "indx.save(index_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # compress index\n",
    "# compressed_name = f'{index_name}.tar.gz'\n",
    "# command = f'tar czvf {compressed_name} {index_file}'\n",
    "# subprocess.check_output(command.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !tar -xzvf dim768-trees13.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Will do, Ill post a link for all of us as soon as the BW meeting ends\n",
      "102751 Will do. Welcome to the gang, Mayankho!\n",
      "414652 will do. The VA certainly doesn't care\n",
      "180632 will do! I am about half finished with the styling\n",
      "87218 will do thanx, once i figure out how LOL\n",
      "79647 I will, at least, try. :fist_bump:\n",
      "152115 I will push the code up to the master branch.\n",
      "89289 I will. I will start as soon as lecture is over.\n",
      "275686 Will do! NY is definitely on my East Coast hit list :fire:\n",
      "316628 That will definitely do it! Lol\n",
      "CPU times: user 742 µs, sys: 34.9 ms, total: 35.7 ms\n",
      "Wall time: 108 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "index = AnnoyIndex(vec_dim, distance_measure_type)\n",
    "index.load(index_file)\n",
    "for i in index.get_nns_by_item(0,10):\n",
    "    print(i, df.cleaned[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = ['issue deploying to heroku']\n",
    "# example = ['how do I deploy a tensorflow model in production?']\n",
    "# vec = tfidf.transform(example)\n",
    "# vec = svd.transform(vec)\n",
    "\n",
    "emb = embedder.encode(example)\n",
    "emb = np.asarray(emb)\n",
    "\n",
    "# combined_example = np.concatenate((emb, vec), axis=1)\n",
    "# combined_example.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17846 Error with useEffect spamming API.\n",
      "224706 Error with useEffect spamming API.\n",
      "76875 conflict in index.css body.less variables.less and login.html\n",
      "9952 having an issue trying to branch\n",
      "208726 having an issue trying to branch\n",
      "266668 uncomment the switch case and default case\n",
      "43030 having issues with login right now\n",
      "27512 its in regard to responsive css\n",
      "159159 Getting fatal error: Permission denied on Git Bash\n",
      "426419 Getting fatal error: Permission denied on Git Bash\n",
      "282449 Reusable Error Validation Pop-Up - ISAAC DONE\n",
      "53042 Having an issue with deploying getting help from a pm\n",
      "375291 Incognito mode is a helluva tool\n",
      "36626 oh.... wow. yeah that's an adjustment\n",
      "273924 Oh No hang in there <@UFGFB8LM9>!!\n",
      "278541 Oh - it's a cirlcle ci yaml file\n",
      "183067 getting errors when trying to run the backend server\n",
      "345055 React Nested Functional Components\n",
      "109249 uh oh <@U9RFV4CBF> has become self aware\n",
      "337909 uh oh <@U9RFV4CBF> has become self aware\n",
      "CPU times: user 9.02 ms, sys: 12.4 ms, total: 21.5 ms\n",
      "Wall time: 97.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in index.get_nns_by_vector(emb.ravel(), 20): # Gets the top 5 similar to unseen example embedding\n",
    "#     print('\\n')\n",
    "    print(i, df.cleaned[i])\n",
    "\n",
    "# Search query: 'tensorflow in production'\n",
    "# Cherry-picked result from the above query w/ full sized embeddings:\n",
    "# '119220 Deploy machine learning models as web servers. <URL>'\n",
    "# None of the words are from the query, but the result has a similar meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
