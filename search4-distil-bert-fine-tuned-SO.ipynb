{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# restart kernel after this\n",
    "!pip install wget annoy\n",
    "!pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this in cli\n",
    "#pip install gpustat && watch -n 0.1 -c gpustat -cp --color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for loading in slack data and cleaning\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "from multiprocessing import Pool\n",
    "\n",
    "# for creating embeddings and index\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from annoy import AnnoyIndex\n",
    "import numpy as np\n",
    "import subprocess\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# for downloading/extracting model from s3\n",
    "import tarfile\n",
    "import tempfile\n",
    "from transformers import cached_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(637568, 2)\n"
     ]
    }
   ],
   "source": [
    "db_string = \"postgresql://postgres:postgres@postgres/postgres\"\n",
    "db = create_engine(db_string)\n",
    "\n",
    "def query_df(line_query, cell_query=None, conn=db):\n",
    "    if cell_query==None:\n",
    "      return pd.read_sql(line_query, conn)\n",
    "    return pd.read_sql(cell_query, conn)\n",
    "\n",
    "parent_query = 'SELECT * FROM message;'\n",
    "reply_query = 'SELECT * FROM reply;'\n",
    "\n",
    "parents = query_df(parent_query)\n",
    "replies = query_df(reply_query)\n",
    "\n",
    "df = pd.concat([parents, replies])\n",
    "df = df[['message_id', 'text']]\n",
    "assert df.isna().sum().sum() == 0\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_whitespace(text):\n",
    "    for r in ((\"\\t\", \" \"), (\"\\n\", \" \"), ('\"', '')):\n",
    "        text = text.replace(*r)\n",
    "    return text\n",
    "\n",
    "def no_url(text):\n",
    "    tokens = text.split()\n",
    "    new = []\n",
    "    for t in tokens:\n",
    "        if 'http' in t:\n",
    "            new.append('<URL>')        \n",
    "        else:\n",
    "            new.append(t)\n",
    "    clean = ' '.join(new)\n",
    "    return clean\n",
    "\n",
    "def no_short_reply(text):\n",
    "    if len(text) < 30:\n",
    "        text = None\n",
    "    return text\n",
    "\n",
    "def cleaner(series):\n",
    "    series = series.apply(no_whitespace)\n",
    "    series = series.apply(no_url)\n",
    "    series = series.apply(no_short_reply)\n",
    "    return series\n",
    "\n",
    "def fast_clean(df):\n",
    "    with Pool(16) as p:\n",
    "        seq = [df.text]\n",
    "        listy = p.map(cleaner, seq)\n",
    "        results = [pd.Series(i) for i in listy]\n",
    "        clean = results[0]\n",
    "    return clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 623 ms, sys: 2.17 s, total: 2.79 s\n",
      "Wall time: 5.84 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df['cleaned'] = fast_clean(df)\n",
    "df = df.dropna()\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 314 ms, sys: 3.7 ms, total: 317 ms\n",
      "Wall time: 316 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "426855"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Drop questions longer than 510 characters.\n",
    "# df = df.loc[df['cleaned'].str.len() < 511]\n",
    "\n",
    "# Shorten messages.\n",
    "df['cleaned'] = df['cleaned'].str.slice(0,510)\n",
    "\n",
    "# Reset index.\n",
    "df = df.reset_index()\n",
    "\n",
    "# Get a list of all the posts/messages.\n",
    "corpus = list(df.cleaned)\n",
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # bert_m_ids = df[['message_id']]\n",
    "# bert_m_ids.to_csv('bert_m_ids.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.6 s, sys: 23.7 ms, total: 5.62 s\n",
      "Wall time: 5.64 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(426855, 88434)"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "vecs = tfidf.fit_transform(df.cleaned)\n",
    "vecs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29.9 s, sys: 34.5 s, total: 1min 4s\n",
      "Wall time: 19.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(426855, 100)"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "svd = TruncatedSVD(n_components=100)\n",
    "reduced = svd.fit_transform(vecs)\n",
    "reduced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.37 s, sys: 405 ms, total: 2.78 s\n",
      "Wall time: 2.59 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): DistilBERT(\n",
       "    (bert): DistilBertModel(\n",
       "      (embeddings): Embeddings(\n",
       "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (transformer): Transformer(\n",
       "        (layer): ModuleList(\n",
       "          (0): TransformerBlock(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (attention): MultiHeadSelfAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "          (1): TransformerBlock(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (attention): MultiHeadSelfAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "          (2): TransformerBlock(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (attention): MultiHeadSelfAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "          (3): TransformerBlock(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (attention): MultiHeadSelfAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "          (4): TransformerBlock(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (attention): MultiHeadSelfAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "          (5): TransformerBlock(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (attention): MultiHeadSelfAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): Pooling()\n",
       ")"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "url = 'https://model-2.s3.us-east-2.amazonaws.com/distil-bert-SO.tar.gz'\n",
    "\n",
    "def download_pretrained_model():\n",
    "    \"\"\" Download and extract finetuned model from S3 \"\"\"\n",
    "    # most of this func from https://github.com/huggingface/transfer-learning-conv-ai/blob/master/utils.py\n",
    "    resolved_archive_file = cached_path(url)\n",
    "    tempdir = tempfile.mkdtemp()\n",
    "    with tarfile.open(resolved_archive_file, 'r:gz') as archive:\n",
    "        archive.extractall(tempdir)\n",
    "    return os.path.join(tempdir, 'model')\n",
    "\n",
    "embedder = SentenceTransformer(download_pretrained_model())\n",
    "embedder.to(\"cuda\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8min 21s, sys: 29.6 s, total: 8min 51s\n",
      "Wall time: 8min 51s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(426855, 768)"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "corpus_embeddings = embedder.encode(corpus)\n",
    "embs = np.asarray(corpus_embeddings)\n",
    "embs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = np.concatenate((embs, reduced),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(426855, 868)"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "CPU times: user 1min 6s, sys: 1.21 s, total: 1min 7s\n",
      "Wall time: 1min 7s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "num_docs, vec_dim = combined.shape\n",
    "distance_measure_type = 'angular'\n",
    "\n",
    "indx = AnnoyIndex(vec_dim, distance_measure_type)\n",
    "for i in range(num_docs):\n",
    "    indx.add_item(i, combined[i])\n",
    "\n",
    "num_trees = int(np.log(num_docs).round(0))\n",
    "# num_trees = 100\n",
    "print(num_trees)\n",
    "indx.build(num_trees)\n",
    "index_name = f'dim{vec_dim}-trees{num_trees}'\n",
    "index_file = f'{index_name}.ann'\n",
    "indx.save(index_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # compress index\n",
    "# compressed_name = f'{index_name}.tar.gz'\n",
    "# command = f'tar czvf {compressed_name} {index_file}'\n",
    "# subprocess.check_output(command.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !tar -xzvf dim768-trees13.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Will do, Ill post a link for all of us as soon as the BW meeting ends\n",
      "388671 They'll post the BW list after the kickoff. This will be the main channel for all things BW. :tada:\n",
      "170951 I’ll drop a link, join whenever you’re ready!\n",
      "8320 Hey everyone, I’ll be dropping a link here at 12:15 for a Q and A\n",
      "160756 err. I'm hanging out and waiting --just lemme know either way and we'll go from there\n",
      "1633 Okay, I’ll drop a link when I’m on.\n",
      "194173 Okay, I’ll drop a link when I’m on.\n",
      "181947 Np! I will DM you the link soon as I have it\n",
      "40089 I think in that meeting we'll iron out who will do what <URL>\n",
      "89930 Good morning everyone good luck on the Sprint- I'll just leave this here. <URL>\n",
      "CPU times: user 13.6 ms, sys: 4.33 ms, total: 18 ms\n",
      "Wall time: 24.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "index = AnnoyIndex(vec_dim, distance_measure_type)\n",
    "index.load(index_file)\n",
    "for i in index.get_nns_by_item(0,10):\n",
    "    print(i, df.cleaned[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 868)"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = ['deploy to heroku']\n",
    "vec = tfidf.transform(example)\n",
    "vec = svd.transform(vec)\n",
    "\n",
    "emb = embedder.encode(example)\n",
    "emb = np.asarray(emb)\n",
    "\n",
    "combined_example = np.concatenate((emb, vec), axis=1)\n",
    "combined_example.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11914 sorry a quick pr for heroku <URL>\n",
      "53042 Having an issue with deploying getting help from a pm\n",
      "216306 Wonder why it automatically deployed that project tho so strange\n",
      "378176 and ensemble it w/ time domain loudness\n",
      "223192 look at the top portion of the css\n",
      "292375 :exploding_head: Mind blown! That makes so much sense!!!\n",
      "417923 READY, TIRED, NERVOUS, EXCITEDDDDD\n",
      "204000 Eh… Super difficult to explain. Jump on in.\n",
      "167493 In the PR to the front end that hits the back end\n",
      "298598 Three cheers for five years? (where the emo kids at)\n",
      "376059 ~Spinning up a spark cluster is hard (not a direct quote)\n",
      "325345 Landslide (Fleetwood Mac) <URL>\n",
      "40243 makes me excited to tackle back end\n",
      "284801 :boom::boom::boom::boom::boom::boom::boom::boom::boom::boom::boom::boom::boom::boom::boom::boom::boom::boom::boom::boom::boom::boom::boom::boom::boom::boom::boom::boom::boom::boom:\n",
      "367313 haha acc hit return without shift\n",
      "127383 Go Kickstarter Success!!!!!!!!!!!!!!!\n",
      "334285 Super flexible but not structured\n",
      "99650 having difficulty with fullName.push\n",
      "312355 having difficulty with fullName.push\n",
      "377998 Spark, Databricks, AWS, GCP, TF, Keras\n",
      "CPU times: user 5.02 ms, sys: 223 µs, total: 5.24 ms\n",
      "Wall time: 8.99 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in index.get_nns_by_vector(combined_example.ravel(), 20): # Gets the top 5 similar to unseen example embedding\n",
    "#     print('\\n')\n",
    "    print(i, df.cleaned[i])\n",
    "\n",
    "# Search query: 'tensorflow in production'\n",
    "# Cherry-picked result from the above query w/ full sized embeddings:\n",
    "# '119220 Deploy machine learning models as web servers. <URL>'\n",
    "# None of the words are from the query, but the result has a similar meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
